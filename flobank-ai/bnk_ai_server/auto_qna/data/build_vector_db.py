import os
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS

# ============================================
# 1) ÏÑ§Ï†ï
# ============================================
TXT_DIR = "/home/g5223sho/bnk_ai_server/auto_qna/data/txt"
DB_DIR = "/home/g5223sho/bnk_ai_server/auto_qna/vector_db"

MAX_CHARS = 1200
OVERLAP = 200


# ============================================
# 2) ÌÖçÏä§Ìä∏ ‚Üí Ï≤≠ÌÇπ Ìï®Ïàò
# ============================================
def chunk_text(text: str, max_chars=MAX_CHARS, overlap=OVERLAP):
    chunks = []
    start = 0
    end = max_chars

    while start < len(text):
        chunk = text[start:end]
        chunks.append(chunk)

        # next window
        start = end - overlap
        end = start + max_chars

    return chunks


# ============================================
# 3) Ìè¥Îçî ÎÇ¥ Î™®Îì† TXT ‚Üí Ï†ÑÏ≤¥ Ï≤≠ÌÅ¨ Î°úÎìú
# ============================================
def load_all_chunks(txt_dir: str):
    if not os.path.exists(txt_dir):
        raise FileNotFoundError(f"‚ùå TXT Ìè¥ÎçîÍ∞Ä ÏóÜÏùå: {txt_dir}")

    chunks = []
    meta = []

    files = os.listdir(txt_dir)
    txt_files = [f for f in files if f.lower().endswith(".txt")]

    print(f"üìÇ TXT ÌååÏùº {len(txt_files)}Í∞ú Î∞úÍ≤¨")

    for fname in txt_files:
        fpath = os.path.join(txt_dir, fname)

        with open(fpath, "r", encoding="utf-8") as f:
            text = f.read()

        file_chunks = chunk_text(text)
        chunks.extend(file_chunks)
        meta.extend([{"source": fname}] * len(file_chunks))

        print(f"üìÑ {fname}: {len(file_chunks)} chunks ÏÉùÏÑ±")

    print(f"\nüìå Ï†ÑÏ≤¥ Ï≤≠ÌÅ¨ Í∞úÏàò: {len(chunks)}")

    return chunks, meta


# ============================================
# 4) Î≤°ÌÑ∞ DB ÏÉùÏÑ±
# ============================================
def build_vector_db():
    # DB Ìè¥Îçî ÏÉùÏÑ±
    os.makedirs(DB_DIR, exist_ok=True)

    # Load chunks
    chunks, metadata = load_all_chunks(TXT_DIR)

    print("\nüîç ÏûÑÎ≤†Îî© ÏÉùÏÑ± ÏãúÏûë (text-embedding-3-large)")
    embedder = OpenAIEmbeddings(model="text-embedding-3-large")

    # Build DB
    db = FAISS.from_texts(chunks, embedder, metadatas=metadata)

    db.save_local(DB_DIR)
    print(f"\nüíæ Î≤°ÌÑ∞ DB Ï†ÄÏû• ÏôÑÎ£å ‚Üí {DB_DIR}")


# ============================================
# 5) Ïã§Ìñâ
# ============================================
if __name__ == "__main__":
    build_vector_db()
