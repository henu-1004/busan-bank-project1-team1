# ================================================
#   rag_build_vectorstore_no_preprocess.py
#   TXT â†’ ì²­í¬ â†’ ì„ë² ë”© â†’ FAISS DB ì €ì¥
# ================================================

import os
from pathlib import Path

from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings




# ----------------------------------------
# 1) TXT ë¡œë”©
# ----------------------------------------
def load_all_txt(directory: str):
    texts = []
    metadata = []

    for file in Path(directory).glob("*.txt"):
        raw = file.read_text(encoding="utf-8", errors="ignore")
        texts.append(raw)
        metadata.append({"source": file.name})

    return texts, metadata


# ----------------------------------------
# 2) ì²­í¬í™”
# ----------------------------------------
def chunk_texts(texts, meta):
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1200,
        chunk_overlap=200
    )

    chunks = []
    metainfo = []

    for text, m in zip(texts, meta):
        split = splitter.split_text(text)
        chunks.extend(split)
        metainfo.extend([m] * len(split))

    return chunks, metainfo


# ----------------------------------------
# 3) ì„ë² ë”© + ë²¡í„°DB ì €ì¥
# ----------------------------------------
def build_vectorstore(chunks, metadata, save_path="faiss_db"):
    embed = OpenAIEmbeddings(model="text-embedding-3-large")

    db = FAISS.from_texts(chunks, embed, metadatas=metadata)
    db.save_local(save_path)

    print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {save_path}/")
    return db


# ----------------------------------------
# 4) ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
# ----------------------------------------
def run_pipeline(txt_dir="data/txt", save_path="faiss_db"):
    print("ğŸ“ TXT ìŠ¤ìº” ì¤‘â€¦")
    texts, meta = load_all_txt(txt_dir)
    print(f"ğŸ“ ì´ {len(texts)}ê°œ íŒŒì¼ ë¡œë“œ ì™„ë£Œ\n")

    print("âœ‚ï¸ ì²­í¬í™” ì¤‘â€¦")
    chunks, metadata = chunk_texts(texts, meta)
    print(f"ì´ ì²­í¬ ê°œìˆ˜: {len(chunks)}\n")

    print("ğŸ§  ì„ë² ë”© + ë²¡í„°DB ìƒì„± ì¤‘â€¦")
    build_vectorstore(chunks, metadata, save_path)

    print("\nğŸš€ ì „ì²´ ì™„ë£Œ!")


if __name__ == "__main__":
    run_pipeline(txt_dir="/home/g5223sho/bnk_ai_server/pdf_Ai/data/txt", save_path="faiss_db")
