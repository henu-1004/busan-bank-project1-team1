# ============================================
#   2nd_preprocessing_llm_restore_only.py
#   SENT íƒœê·¸ ê¸°ë°˜ â†’ LLM êµ¬ì¡° ë³µì› (ì²­í‚¹ ì—†ìŒ)
# ============================================

from openai import OpenAI
import re

client = OpenAI()

# --------------------------------------------
# SYSTEM í”„ë¡¬í”„íŠ¸ â€” ì›ë¬¸ ë³µì› ì „ìš©
# --------------------------------------------
SYSTEM_PROMPT = """
ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” PDF â†’ í…ìŠ¤íŠ¸ â†’ ë¬¸ì¥ ë¶„ë¦¬ ê³¼ì •ì—ì„œ ìƒì„±ëœ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ë¥¼
ì›ë˜ ë¬¸ì„œ êµ¬ì¡°ë¡œ ë³µì›í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ì´ í…ìŠ¤íŠ¸ëŠ” <<<!SENT_xxxx!>>> ê°™ì€ íƒœê·¸ ê¸°ì¤€ìœ¼ë¡œ ì¸ìœ„ì ìœ¼ë¡œ ì˜ë ¤ ìˆìŠµë‹ˆë‹¤.
ë‹¤ìŒ ê·œì¹™ì„ ë°˜ë“œì‹œ ì§€í‚¤ì„¸ìš”:

1. ì›ë¬¸ì˜ ë‹¨ì–´, ìˆ«ì, ê¸°í˜¸, í‘œê¸°ë²•ì€ ì ˆëŒ€ ìˆ˜ì •í•˜ê±°ë‚˜ ì œê±°í•˜ì§€ ë§ ê²ƒ
2. ëª¨ë“  SENT íƒœê·¸ëŠ” ì™„ì „íˆ ì œê±°í•  ê²ƒ
3. ì˜ë¦° ë¬¸ì¥ì€ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ë¶™ì¼ ê²ƒ
4. í‘œ/ë¶ˆë¦¿/ë¦¬ìŠ¤íŠ¸ëŠ” í•˜ë‚˜ì˜ ë¸”ë¡ìœ¼ë¡œ ìœ ì§€
5. ê°œí–‰ì€ ì›ë˜ ë¬¸ì„œ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë©´ì„œ ì •ë¦¬
6. ë¬¸ì¥ì˜ ìˆœì„œëŠ” ì ˆëŒ€ ë³€ê²½í•˜ì§€ ë§ ê²ƒ
7. ìš”ì•½ ê¸ˆì§€, ìƒˆë¡œìš´ ë¬¸ì¥ ìƒì„± ê¸ˆì§€
8. ì¶œë ¥ì€ ì˜¤ì§ ë³µì›ëœ ì›ë¬¸ë§Œ í¬í•¨
"""


# --------------------------------------------
# LLM í˜¸ì¶œ í•¨ìˆ˜ â€” ë³µì›ë§Œ ìˆ˜í–‰
# --------------------------------------------
def ask_llm(prev_overlap: str, chunk: str, next_overlap: str):
    user_payload = f"""
ì•„ë˜ ì„¸ êµ¬ê°„ì€ ì›ë¬¸ì—ì„œ ì„œë¡œ ì´ì–´ì§€ëŠ” ì‹¤ì œ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.

[previous_overlap]
{prev_overlap}

[current_chunk]
{chunk}

[next_overlap]
{next_overlap}

ìš”ì²­:
- ì„¸ êµ¬ê°„ì„ ì°¸ê³ í•˜ì—¬, í˜„ì¬ chunkì˜ ë¬¸ì¥ê³¼ êµ¬ì¡°ë¥¼ ì›ë¬¸ ê·¸ëŒ€ë¡œ ì •í™•íˆ ë³µì›í•´ ì£¼ì„¸ìš”.
- ë³µì›ëœ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
- previous_overlap ë˜ëŠ” next_overlapì— í¬í•¨ëœ ë¬¸ì¥ì„ ì¤‘ë³µ ìƒì„±í•˜ì§€ ë§ ê²ƒ
- overlapì€ ì°¸ê³ ìš©ì´ë©°, ì´ë¯¸ í¬í•¨ëœ êµ¬ë¬¸ì€ ë°˜ë³µ ì¶œë ¥ ê¸ˆì§€
"""
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_payload},
        ],
        temperature=0.0
    )
    return response.choices[0].message.content


# --------------------------------------------
# ìŠ¬ë¼ì´ë”© ìœˆë„ìš°
# --------------------------------------------
def sliding_window_text(text, size=7000, overlap=1000):
    chunks = []
    starts = []
    start = 0
    total = len(text)

    while start < total:
        end = min(start + size, total)
        chunks.append(text[start:end])
        starts.append(start)
        start += (size - overlap)

    return chunks, starts


# --------------------------------------------
# SENT ë¦¬ìŠ¤íŠ¸ â†’ raw text ë³‘í•©
# --------------------------------------------
def load_raw_text_with_tags(path: str):
    merged = []
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue

            # [123] ì œê±°
            line = re.sub(r"^\s*\[\d+\]\s*", "", line)
            merged.append(line)
    return "\n".join(merged)


# --------------------------------------------
# ì‹¤í–‰ë¶€
# --------------------------------------------
if __name__ == "__main__":

    input_path = "/home/g5223sho/bnk_ai_server/pdf_Ai/pdf_comment/test/pdf_temp/FLOBANK ë” ì™€ì´ë“œ ìƒí’ˆì„¤ëª…ì„œ.txt_sentences.txt"
    output_path = "/home/g5223sho/bnk_ai_server/pdf_Ai/pdf_comment/test/pdf_temp/FLOBANK ë” ì™€ì´ë“œ ìƒí’ˆì„¤ëª…ì„œ_restored.txt"

    print("ğŸ“„ ì…ë ¥ íŒŒì¼ ë¡œë“œ ì¤‘â€¦")
    raw_text = load_raw_text_with_tags(input_path)

    print("ğŸ”— ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ìƒì„±â€¦")
    win_chunks, starts = sliding_window_text(raw_text)

    outputs = []
    total = len(win_chunks)

    print("ğŸ§  LLM ì›ë¬¸ ë³µì› ìš”ì²­ ì¤‘â€¦")
    for i, chunk in enumerate(win_chunks):
        print(f" - ì²˜ë¦¬ ì¤‘: {i+1}/{total}")

        text = chunk.strip()
        if len(text) == 0:
            print("   â†’ ë¹ˆ chunk â†’ ìŠ¤í‚µ")
            continue

        prev_overlap = raw_text[max(0, starts[i] - 1000): starts[i]] if i > 0 else ""
        next_overlap = raw_text[starts[i] + len(chunk): starts[i] + len(chunk) + 1000] if i < total - 1 else ""

        out = ask_llm(prev_overlap, chunk, next_overlap)
        outputs.append(out)

    print("ğŸ“¦ ì „ì²´ ë³µì› ë³‘í•© ì¤‘â€¦")
    final_text = "\n".join(outputs)

    print("ğŸ’¾ ì €ì¥ ì¤‘â€¦")
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(final_text)

    print("âœ… ì™„ë£Œ! ì €ì¥ë¨:", output_path)
