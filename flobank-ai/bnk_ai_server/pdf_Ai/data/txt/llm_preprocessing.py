# ================================================
#   llm_auto_preprocess.py
#   LLM ê¸°ë°˜ Adaptive Chunking + Safe Cleaning
#   (ëª¨ë“  ì¶œë ¥ì€ ver_llm_preprocessing/ ì•„ë˜ ì €ì¥)
# ================================================

import os
import re
import json
from pathlib import Path
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)


# =================================================
# 0) í™”ì´íŠ¸ìŠ¤í˜ì´ìŠ¤ Normalize
# =================================================

def normalize_ws(text: str):
    return re.sub(r"\s+", "", text)


# =================================================
# 1) LLM ê¸°ë°˜ ë¬¸ì„œ chunking
# =================================================

def llm_chunk_document(full_text: str):

    prompt = f"""
ë„ˆëŠ” ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ ì „ë¬¸ê°€ë‹¤.

ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ 'ì˜ë¯¸ ë‹¨ìœ„(chunk)'ë¡œ ë¶„ë¦¬í•˜ë¼.
chunk ê°œìˆ˜ëŠ” 5~50ê°œ ì‚¬ì´ë¡œ ì•ˆì •ì ìœ¼ë¡œ ìƒì„±í•˜ë¼.

ì¶œë ¥ í˜•ì‹ (JSON ì½”ë“œë¸”ë¡ ê¸ˆì§€):
chunks: [
  {{
    "title": "ìš”ì•½ ì œëª©",
    "content": "í•´ë‹¹ chunkì˜ ì›ë¬¸ (ì ˆëŒ€ ìˆ˜ì • ê¸ˆì§€)"
  }},
  ...
]

ê·œì¹™:
- ì›ë¬¸ ìˆ˜ì •/ì‚­ì œ/ì¶”ê°€ ê¸ˆì§€
- OCR ì˜¤ë¥˜ ìˆì–´ë„ ì›ë¬¸ ê·¸ëŒ€ë¡œ ìœ ì§€
- í‘œëŠ” í•˜ë‚˜ì˜ chunkë¡œ ë¬¶ê¸°
- ì¡°ë¬¸/í•­ëª©/ì ˆ ë‹¨ìœ„ë„ chunk ì‹œì‘ì  ë  ìˆ˜ ìˆìŒ
- ì œëª©(title)ì€ ì§§ê²Œ 3~10ì

ë¬¸ì„œ ì „ì²´:

======================
{full_text}
======================

ìœ„ ê·œì¹™ëŒ€ë¡œ chunk ëª©ë¡ì„ ë§Œë“¤ì–´ë¼.
"""

    return llm.invoke(prompt).content


# =================================================
# 2) JSON-like chunk íŒŒì‹±
# =================================================

def parse_llm_chunks(raw_text: str):

    match = re.search(r"chunks\s*:\s*\[(.*)\]", raw_text, re.DOTALL)
    if not match:
        return []

    body = match.group(1)

    text_json = "[" + body + "]"
    text_json = text_json.replace("\n", " ")
    text_json = re.sub(r",\s*}", "}", text_json)

    try:
        chunks = json.loads(text_json)
    except:
        chunks = [{"title": "chunk", "content": body}]

    final_chunks = []
    for c in chunks:
        if "content" in c:
            final_chunks.append(c["content"].strip())

    return final_chunks


# =================================================
# 3) chunkë³„ ì•ˆì „ ì „ì²˜ë¦¬
# =================================================

def preprocess_chunk_safe(chunk: str):

    prompt = f"""
ë„ˆëŠ” ë¬¸ì„œ ì „ì²˜ë¦¬ ì „ë¬¸ê°€ë‹¤.

ì¡°ê±´:
- ì›ë¬¸ ë‹¨ì–´/ë¬¸ì¥ ì ˆëŒ€ ìˆ˜ì • ê¸ˆì§€
- OCRë¡œ ë¶™ì€ ë¬¸ì¥ë§Œ ë¶„ë¦¬ ê°€ëŠ¥
- ë¦¬ìŠ¤íŠ¸ëŠ” í•­ëª© ë‹¨ìœ„ ì¤„ë°”ê¿ˆ
- í‘œëŠ” í–‰ ë‹¨ìœ„ ì •ë ¬
- ë‚´ìš© ì‚­ì œ/ì¶”ê°€/ë³€ê²½ ê¸ˆì§€

[ì²­í¬]
{chunk}

ìœ„ ì›ë¬¸ì„ ì‚¬ëŒì´ ì½ê¸° ì¢‹ê²Œ ì •ë¦¬í•˜ë˜,
ì›ë¬¸ì˜ ì˜ë¯¸ì™€ ë‹¨ì–´ëŠ” ì ˆëŒ€ ë°”ê¾¸ì§€ ë§ˆë¼.
"""

    cleaned = llm.invoke(prompt).content

    # diff ê²€ì‚¬ (WS ì œê±° í›„ ë¹„êµ)
    if normalize_ws(cleaned) != normalize_ws(chunk):
        return chunk
    else:
        return cleaned


# =================================================
# 4) ì „ì²´ txt íŒŒì¼ ì²˜ë¦¬ with ver_llm_preprocessing/
# =================================================

def process_txt_file(path: Path):

    print(f"\nğŸ“„ ì²˜ë¦¬ ì‹œì‘: {path}")

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    out_dir = path.parent / "ver_llm_preprocessing"
    out_dir.mkdir(exist_ok=True)

    full_text = path.read_text(encoding="utf-8", errors="ignore")

    # (1) LLM chunking ìˆ˜í–‰
    print("ğŸ” LLM ê¸°ë°˜ chunk ë¶„ì„ ì¤‘...")
    raw_chunk_text = llm_chunk_document(full_text)

    # chunk êµ¬ì¡° ì €ì¥
    chunk_struct_path = out_dir / f"{path.stem}_chunk_structure.txt"
    chunk_struct_path.write_text(raw_chunk_text, encoding="utf-8")

    # (2) chunk íŒŒì‹±
    chunks = parse_llm_chunks(raw_chunk_text)
    print(f"âœ” LLMì´ ìƒì„±í•œ chunk ê°œìˆ˜: {len(chunks)}")

    # (3) chunkë³„ safe cleaning
    processed_chunks = []

    for idx, c in enumerate(chunks):
        print(f"  â¤ chunk {idx+1}/{len(chunks)} ì „ì²˜ë¦¬ ì¤‘...")
        try:
            cleaned = preprocess_chunk_safe(c)
        except:
            cleaned = c
        processed_chunks.append(cleaned)

    # (4) ìµœì¢… ì €ì¥
    out_path = out_dir / f"{path.stem}_llm_preprocessed.txt"
    out_path.write_text("\n\n".join(processed_chunks), encoding="utf-8")

    print(f"âœ… ì €ì¥ ì™„ë£Œ: {out_path}")


# =================================================
# 5) ì „ì²´ í´ë” ì²˜ë¦¬
# =================================================

def process_all_txt(directory: str):
    for f in Path(directory).glob("*.txt"):
        process_txt_file(f)


# =================================================
# 6) ì‹¤í–‰
# =================================================

if __name__ == "__main__":
    process_all_txt("/home/g5223sho/bnk_ai_server/pdf_Ai/data/txt")
