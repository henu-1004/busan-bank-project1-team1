# ===========================
#     summarize_articles.py
# ===========================

import os
import json
import time
import traceback
from datetime import datetime

import torch
from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration


# -------------------------------------------------------------
# ëª¨ë¸ ë¡œë”©
# -------------------------------------------------------------
print("ðŸ“Œ Loading KoBART Summarization Model...")

tokenizer = PreTrainedTokenizerFast.from_pretrained("gogamza/kobart-summarization")
model = BartForConditionalGeneration.from_pretrained("gogamza/kobart-summarization")

device = "cuda" if torch.cuda.is_available() else "cpu"
model = model.to(device)

print(f"ðŸš€ Model Loaded on: {device}")


# -------------------------------------------------------------
# ì—ëŸ¬ ë¡œê·¸ ì €ìž¥
# -------------------------------------------------------------
def log_error(msg):
    with open("summary_error.log", "a", encoding="utf-8") as f:
        f.write(f"[{datetime.now()}] {msg}\n")
        f.write(traceback.format_exc() + "\n\n")


# -------------------------------------------------------------
# ìš”ì•½ í•¨ìˆ˜
# -------------------------------------------------------------
def summarize_text(text: str) -> str:
    try:
        if not text or len(text.strip()) < 20:
            return ""

        text = text.replace("\n", " ")
        text = " ".join(text.split())
        text = text[:3000]

        inputs = tokenizer(
            text,
            return_tensors="pt",
            max_length=1024,
            truncation=True
        ).to(device)

        summary_ids = model.generate(
            inputs["input_ids"],
            max_length=120,
            min_length=30,
            num_beams=4,
            early_stopping=True
        )

        result = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
        return result.strip()

    except Exception as e:
        log_error(f"ìš”ì•½ ì‹¤íŒ¨: {e}")
        return ""


# -------------------------------------------------------------
# JSON í•˜ë‚˜ ìš”ì•½
# -------------------------------------------------------------
def summarize_file(json_path: str, out_dir="summaries"):
    print(f"\nðŸ“„ ì²˜ë¦¬ íŒŒì¼: {json_path}")

    if not os.path.exists(json_path):
        print("âŒ íŒŒì¼ ì—†ìŒ:", json_path)
        return

    os.makedirs(out_dir, exist_ok=True)

    base = os.path.basename(json_path)
    out_path = os.path.join(out_dir, base.replace(".json", "_summary.json"))

    # ì´ë¯¸ ìš”ì•½ëœ íŒŒì¼ì´ë©´ ìŠ¤í‚µ
    if os.path.exists(out_path):
        print(f"â© ì´ë¯¸ ìš”ì•½ëœ íŒŒì¼ ì¡´ìž¬ â†’ ìŠ¤í‚µ: {out_path}")
        return

    try:
        with open(json_path, "r", encoding="utf-8") as f:
            articles = json.load(f)
    except:
        log_error(f"JSON ë¡œë”© ì‹¤íŒ¨: {json_path}")
        return

    # ìš”ì•½ ì²˜ë¦¬
    for i, art in enumerate(articles):
        if art.get("summary_ai"):
            print(f"â© {i+1}/{len(articles)} ì´ë¯¸ ìš”ì•½ë¨ â†’ ìŠ¤í‚µ")
            continue

        print(f"  â–¶ {i+1}/{len(articles)} ìš”ì•½ ì¤‘...")

        text_to_summarize = (
            f"{art.get('title','')}\n"
            f"{art.get('summary','')}\n"
            f"{art.get('content','')}"
        )

        art["summary_ai"] = summarize_text(text_to_summarize)
        time.sleep(0.2)

    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(articles, f, ensure_ascii=False, indent=4)

    print(f"âœ¨ ì €ìž¥ ì™„ë£Œ â†’ {out_path}")


# -------------------------------------------------------------
# ì‹¤í–‰ (ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ íŒŒì¼ë§Œ ìš”ì•½)
# -------------------------------------------------------------
if __name__ == "__main__":

    # ðŸ”¥ ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€
    today_str = datetime.now().strftime("%Y%m%d")

    print(f"\nðŸ“Œ ì˜¤ëŠ˜ ë‚ ì§œ({today_str}) ê¸°ì¤€ ìš”ì•½í•  íŒŒì¼ ì„ íƒ ì¤‘...\n")

    # ðŸ”¥ íŒŒì¼ í•„í„°ë§: ì˜¤ëŠ˜ ë‚ ì§œ + .json
    targets = [
        f for f in os.listdir(".")
        if f.endswith(".json") and today_str in f
    ]

    if not targets:
        print("âŒ ì˜¤ëŠ˜ ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        exit()

    print("ðŸ“Œ ìš”ì•½ ëŒ€ìƒ JSON íŒŒì¼:")
    for t in targets:
        print(" -", t)

    for file in targets:
        summarize_file(file)
