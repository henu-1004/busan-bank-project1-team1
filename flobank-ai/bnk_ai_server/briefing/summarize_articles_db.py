# ===============================================
#   summarize_articles_db.py  
#   TB_ARTICLEì— SUMMARY_AI ìƒì„±/ì—…ë°ì´íŠ¸
# ===============================================

import traceback
import time
from datetime import datetime

import torch
from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration

from db import get_conn   # ðŸ”¥ DB connection (Thin mode)

# -------------------------------------------------------------
# ëª¨ë¸ ë¡œë”©
# -------------------------------------------------------------
print("ðŸ“Œ Loading KoBART Summarization Model...")

tokenizer = PreTrainedTokenizerFast.from_pretrained("gogamza/kobart-summarization")
model = BartForConditionalGeneration.from_pretrained("gogamza/kobart-summarization")

device = "cuda" if torch.cuda.is_available() else "cpu" 
model = model.to(device)

print(f"ðŸš€ Model Loaded on: {device}")


# -------------------------------------------------------------
# ðŸ”¥ [í‘œ] ê¸°ì‚¬ íŒë³„ í•¨ìˆ˜
# -------------------------------------------------------------
def is_table_article(title: str) -> bool:
    return "[í‘œ]" in title


# -------------------------------------------------------------
# ë¡œê·¸ ì €ìž¥
# -------------------------------------------------------------
def log_error(msg):
    with open("summary_error.log", "a", encoding="utf-8") as f:
        f.write(f"[{datetime.now()}] {msg}\n")
        f.write(traceback.format_exc() + "\n\n")


# -------------------------------------------------------------
# ìš”ì•½ í•¨ìˆ˜ (KoBART)
# -------------------------------------------------------------
def summarize_text(text: str) -> str:
    try:
        if not text or len(text.strip()) < 20:
            return ""

        text = text.replace("\n", " ")
        text = " ".join(text.split())
        text = text[:3000]

        inputs = tokenizer(
            text,
            return_tensors="pt",
            max_length=1024,
            truncation=True
        ).to(device)

        summary_ids = model.generate(
            inputs["input_ids"],
            max_length=120,
            min_length=30,
            num_beams=4,
            early_stopping=True
        )

        result = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
        return result.strip()

    except Exception as e:
        log_error(f"ìš”ì•½ ì‹¤íŒ¨: {e}")
        return ""


# -------------------------------------------------------------
# DBì—ì„œ SUMMARY_AIê°€ NULLì¸ ê¸°ì‚¬ ë¶ˆëŸ¬ì˜¤ê¸° (CLOB â†’ str ë³€í™˜)
# -------------------------------------------------------------
def fetch_articles_without_ai():
    conn = get_conn()
    cur = conn.cursor()

    sql = """
        SELECT ARTICLE_ID, TITLE, SUMMARY, CONTENT
          FROM TB_ARTICLE
         WHERE SUMMARY_AI IS NULL
         ORDER BY WRITTEN_AT DESC
    """

    cur.execute(sql)

    rows = []
    for article_id, title, summary, content in cur:

        # ðŸ”¥ CLOB â†’ ë¬¸ìžì—´ ë³€í™˜
        if hasattr(summary, "read"):
            summary = summary.read()

        if hasattr(content, "read"):
            content = content.read()

        rows.append((article_id, title, summary, content))

    cur.close()
    conn.close()

    return rows


# -------------------------------------------------------------
# SUMMARY_AI ì—…ë°ì´íŠ¸
# -------------------------------------------------------------
def update_summary_ai(article_id, text):
    conn = get_conn()
    cur = conn.cursor()

    sql = """
        UPDATE TB_ARTICLE
           SET SUMMARY_AI = :summary_ai,
               UPDATED_AT = CURRENT_TIMESTAMP
         WHERE ARTICLE_ID = :article_id
    """

    cur.execute(sql, {"summary_ai": text, "article_id": article_id})
    conn.commit()

    cur.close()
    conn.close()


# -------------------------------------------------------------
# ì „ì²´ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸
# -------------------------------------------------------------
def process_summary_ai():
    rows = fetch_articles_without_ai()

    print(f"\nðŸ“Œ SUMMARY_AI ìƒì„± í•„ìš” ê¸°ì‚¬: {len(rows)}ê°œ")

    if not rows:
        print("â© ìƒˆ ìš”ì•½ ìž‘ì—… ì—†ìŒ.")
        return

    for article_id, title, summary, content in rows:
        print(f"\nðŸ“ ìš”ì•½ ì¤‘: [{article_id}] {title}")

        # ---------------------------------------------------------
        # ðŸ”¥ [í‘œ] í•„í„°ë§: í‘œ ê¸°ë°˜ ê¸°ì‚¬ëŠ” ìš”ì•½ ê±´ë„ˆë›°ê³  ê³ ì • ë¬¸êµ¬ ì €ìž¥
        # ---------------------------------------------------------
        if is_table_article(title):
            fixed_summary = "í‘œ/í˜•ì‹ ê¸°ë°˜ ê¸°ì‚¬ìž…ë‹ˆë‹¤."
            update_summary_ai(article_id, fixed_summary)
            print(f"â© [í‘œ] ê¸°ì‚¬ ì²˜ë¦¬ ì™„ë£Œ (ARTICLE_ID={article_id})")
            continue

        # ---------------------------------------------------------
        # ðŸ”¥ ì¼ë°˜ ê¸°ì‚¬ ìš”ì•½
        # ---------------------------------------------------------
        combined_text = f"{title}\n{summary}\n{content}"
        ai_summary = summarize_text(combined_text)

        update_summary_ai(article_id, ai_summary)

        print(f"âœ” ì €ìž¥ ì™„ë£Œ (ARTICLE_ID={article_id})")
        time.sleep(0.2)


# -------------------------------------------------------------
# ì‹¤í–‰
# -------------------------------------------------------------
if __name__ == "__main__":
    process_summary_ai()
